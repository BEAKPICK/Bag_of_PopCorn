{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "tutorial-part-4.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_CS3TOdz38r",
        "colab_type": "text"
      },
      "source": [
        "# Bag of Words Meets Bags of Popcorn\n",
        "\n",
        "* 캐글 경진대회 링크 : https://www.kaggle.com/c/word2vec-nlp-tutorial\n",
        "\n",
        "# 튜토리얼 파트 4 번외\n",
        "* tf-idf를 통해 벡터화 해보고 k_fold 를 사용해서 cross_validation 을 해본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUZ7Spvfz38t",
        "colab_type": "code",
        "colab": {},
        "outputId": "86e95e0f-767d-48a3-d460-dd712963ae5e"
      },
      "source": [
        "import pandas as pd\n",
        "\"\"\"\n",
        "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며 \n",
        "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
        "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
        "\"\"\"\n",
        "# QUOTE_MINIMAL (0), QUOTE_ALL (1), \n",
        "# QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
        "\n",
        "# 레이블인 sentiment 가 있는 학습 데이터\n",
        "train = pd.read_csv('data/labeledTrainData.tsv', \n",
        "                    header=0, delimiter='\\t', quoting=3)\n",
        "# 레이블이 없는 테스트 데이터\n",
        "test = pd.read_csv('data/testData.tsv', \n",
        "                   header=0, delimiter='\\t', quoting=3)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 3)\n",
            "(25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kphKTk8gz38x",
        "colab_type": "code",
        "colab": {},
        "outputId": "c27fb92c-3ea8-47ab-da52-702e96ae6a85"
      },
      "source": [
        "# 긍정과 부정 리뷰가 어떻게 들어있는지 카운트 해본다.\n",
        "# 긍정과 부정리뷰가 각각 동일하게 12,500개씩 들어있다.\n",
        "train['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12500\n",
              "0    12500\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qulrT-6gz387",
        "colab_type": "code",
        "colab": {},
        "outputId": "02c7bb6f-32be-462b-d719-bb7da37924b2"
      },
      "source": [
        "# 학습데이터에는 sentiment 데이터가 있다.\n",
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 3 columns):\n",
            "id           25000 non-null object\n",
            "sentiment    25000 non-null int64\n",
            "review       25000 non-null object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 586.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9WAu-64z39A",
        "colab_type": "code",
        "colab": {},
        "outputId": "796c1935-a693-4cb8-891e-f114c26cb316"
      },
      "source": [
        "# 테스트 데이터에는 sentiment가 없으며 이 sentiment를 예측하는 게 이 경진대회의 미션이다.\n",
        "test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 2 columns):\n",
            "id        25000 non-null object\n",
            "review    25000 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 390.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8t2Qglz39F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리는 튜토리얼 파트1~4까지 공통으로 사용되기 때문에 별도의 파이썬 파일로 분리했다.\n",
        "# 그리고 캐글에 있는 코드를 병렬처리하도록 멀티프로세싱 코드를 추가했다.\n",
        "# 하지만 여기에서는 멀티프로세싱 코드만 임포트해서 사용하고 전처리는 태그만 제거해주도록 한다.\n",
        "# 그리고 WordNetLemmatizer로 레마타이징 한다.\n",
        "# 음소표기법(lemmatization)은 튜토리얼 파트1에 설명 되어 있고 다음 링크에 있다.\n",
        "# https://github.com/corazzon/KaggleStruggle/blob/master/word2vec-nlp-tutorial/tutorial-part-1.ipynb\n",
        "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def review_to_words( raw_review ):\n",
        "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
        "    review_text = wordnet_lemmatizer.lemmatize(review_text)\n",
        "    return review_text "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9em3XWM9z39L",
        "colab_type": "code",
        "colab": {},
        "outputId": "0238b688-45a7-4165-8b21-8d9047aa7968"
      },
      "source": [
        "# 학습데이터를 전처리 한다.\n",
        "%time train['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    train['review'], review_to_words, workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 118 ms, sys: 130 ms, total: 248 ms\n",
            "Wall time: 6.65 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2anUZ7BQz39Q",
        "colab_type": "code",
        "colab": {},
        "outputId": "c6b970e0-6cda-47b1-820d-8a53a9d1b558"
      },
      "source": [
        "# 학습데이터와 동일하게 테스트 데이터에 대해서도 전처리 한다.\n",
        "%time test['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    test['review'], review_to_words, workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 132 ms, sys: 189 ms, total: 321 ms\n",
            "Wall time: 6.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSTJKLZjz39V",
        "colab_type": "code",
        "colab": {},
        "outputId": "5cf1d999-a4ae-4433-8670-08eb6a155b98"
      },
      "source": [
        "# 전처리한 학습 데이터 10개만을 불러와서 본다.\n",
        "train['review_clean'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \"With all this stuff going down at the moment ...\n",
              "1    \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2    \"The film starts with a manager (Nicholas Bell...\n",
              "3    \"It must be assumed that those who praised thi...\n",
              "4    \"Superbly trashy and wondrously unpretentious ...\n",
              "5    \"I dont know why people think this is such a b...\n",
              "6    \"This movie could have been very good, but com...\n",
              "7    \"I watched this video at a friend's house. I'm...\n",
              "8    \"A friend of mine bought this film for £1, and...\n",
              "9    \"This movie is full of references. Like \\\"Mad ...\n",
              "Name: review_clean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW6A9VaGz39Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "17c3d2d0-0fec-4095-bceb-16106478914c"
      },
      "source": [
        "# 전처리한 테스트 데이터 10개만을 불러와서 본다.\n",
        "test['review_clean'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \"Naturally in a film who's main themes are of ...\n",
              "1    \"This movie is a disaster within a disaster fi...\n",
              "2    \"All in all, this is a movie for kids. We saw ...\n",
              "3    \"Afraid of the Dark left me with the impressio...\n",
              "4    \"A very accurate depiction of small time mob l...\n",
              "5    \"...as valuable as King Tut's tomb! (OK, maybe...\n",
              "6    \"This has to be one of the biggest misfires ev...\n",
              "7    \"This is one of those movies I watched, and wo...\n",
              "8    \"The worst movie i've seen in years (and i've ...\n",
              "9    \"Five medical students (Kevin Bacon, David Lab...\n",
              "Name: review_clean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21-ul8E9z39c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train과 X_test에 리뷰 데이터를 담아주고 이 데이터를 TF-IDF를 통해 임베딩(벡터화)해본다. \n",
        "X_train = train['review_clean']\n",
        "X_test = test['review_clean']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY9aTs-kz39f",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n",
        "TF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값으로, 이 값이 높을수록 문서에서 중요하다고 생각할 수 있다. 하지만 단어 자체가 문서군 내에서 자주 사용되는 경우, 이것은 그 단어가 흔하게 등장한다는 것을 의미한다. 이것을 DF(문서 빈도, document frequency)라고 하며, 이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 한다. TF-IDF는 TF와 IDF를 곱한 값이다.\n",
        "\n",
        "IDF 값은 문서군의 성격에 따라 결정된다. 예를 들어 '원자'라는 낱말은 일반적인 문서들 사이에서는 잘 나오지 않기 때문에 IDF 값이 높아지고 문서의 핵심어가 될 수 있지만, 원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 각 문서들을 세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.\n",
        "\n",
        "역문서 빈도(IDF)는 한 단어가 문서 집합 전체에서 얼마나 공통적으로 나타나는지를 나타내는 값이다. 전체 문서의 수를 해당 단어를 포함한 문서의 수로 나눈 뒤 로그를 취하여 얻을 수 있다.\n",
        "\n",
        "* 출처 : [TF-IDF - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/TF-IDF)\n",
        "\n",
        "\\begin{equation*}\n",
        "\\text{tfidf}(w, d) = \\text{tf} \\times (\\log\\big(\\frac{N + 1}{N_w + 1}\\big) + 1)\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "* 싸이킷런 공식문서 : [4.2. Feature extraction — scikit-learn 0.19.1 documentation](http://scikit-learn.org/stable/modules/feature_extraction.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S0dp562z39f",
        "colab_type": "code",
        "colab": {},
        "outputId": "45098c79-fc1d-4d47-a8d6-0ebb9931f719"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import words\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer = 'word', \n",
        "                             lowercase = True,\n",
        "                             tokenizer = None,\n",
        "                             preprocessor = None,\n",
        "                             stop_words = 'english',\n",
        "                             min_df = 2, # 토큰이 나타날 최소 문서 개수로 오타나 자주 나오지 않는 특수한 전문용어 제거에 좋다. \n",
        "                             ngram_range=(1, 3),\n",
        "                             vocabulary = set(words.words()), # nltk의 words를 사용하거나 문서 자체의 사전을 만들거나 선택한다. \n",
        "                             max_features = 90000\n",
        "                            )\n",
        "vectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
              "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None,\n",
              "        vocabulary={'bromopicrin', 'preinhere', 'hypsilophodontid', 'subjectivistic', 'paleocyclic', 'severity', 'Puccinia', 'octadecane', 'brennage', 'kerykeion', 'preconsideration', 'postcanonical', 'catadioptrical', 'Neobeckia', 'Pantotheria', 'misotheism', 'gummage', 'halting', 'unmottled', 'phalangal',... 'litigious', 'vermicle', 'bonhomie', 'typhus', 'jocuma', 'believe', 'evangelistary', 'Podophyllum'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92HRVtcmz39k",
        "colab_type": "text"
      },
      "source": [
        "### TfidfTransformer()\n",
        "* norm='l2' 각 문서의 피처 벡터를 어떻게 벡터 정규화 할지 정한다. \n",
        "    - L2 : 벡터의 각 원소의 제곱의 합이 1이 되도록 만드는 것이고 기본 값\n",
        "    - L1 : 벡터의 각 원소의 절댓값의 합이 1이 되도록 크기를 조절\n",
        "* smooth_idf=False\n",
        "    - 피처를 만들 때 0으로 나오는 항목에 대해 작은 값을 더해서(스무딩을 해서) 피처를 만들지 아니면 그냥 생성할지를 결정\n",
        "* sublinear_tf=False\n",
        "* use_idf=True\n",
        "    - TF-IDF를 사용해 피처를 만들 것인지 아니면 단어 빈도 자체를 사용할 것인지 여부"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLjMaNbfz39k",
        "colab_type": "code",
        "colab": {},
        "outputId": "1757d479-b253-4368-b84d-fd35bd48c578"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "    ('tfidf', TfidfTransformer(smooth_idf = False)),\n",
        "])  \n",
        "pipeline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
              "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
              "       ...('tfidf', TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False,\n",
              "         use_idf=True))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "voRjcFJqz39n",
        "colab_type": "code",
        "colab": {},
        "outputId": "8129b1eb-487b-430a-842c-666dfba9650a"
      },
      "source": [
        "%time X_train_tfidf_vector = pipeline.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.2 s, sys: 119 ms, total: 10.3 s\n",
            "Wall time: 10.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/corazzon/codes/jupyter/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(float(n_samples) / df) + 1.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxF_nn9fz39r",
        "colab_type": "code",
        "colab": {},
        "outputId": "3e5d2cfe-1a3a-4892-e970-52981a84cfcc"
      },
      "source": [
        "vocab = vectorizer.get_feature_names()\n",
        "print(len(vocab))\n",
        "vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'Aani',\n",
              " 'Aaron',\n",
              " 'Aaronic',\n",
              " 'Aaronical',\n",
              " 'Aaronite',\n",
              " 'Aaronitic',\n",
              " 'Aaru',\n",
              " 'Ab',\n",
              " 'Ababdeh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkvy2HTyz39w",
        "colab_type": "code",
        "colab": {},
        "outputId": "b54a783a-e657-4f5a-87de-3f48fd0b84d9"
      },
      "source": [
        "%time X_test_tfidf_vector = pipeline.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.58 s, sys: 93.8 ms, total: 9.67 s\n",
            "Wall time: 9.72 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/corazzon/codes/jupyter/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(float(n_samples) / df) + 1.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waksho_jz391",
        "colab_type": "code",
        "colab": {},
        "outputId": "914d8aac-d953-4bc5-f051-92cd19764fc5"
      },
      "source": [
        "import numpy as np\n",
        "dist = np.sum(X_train_tfidf_vector, axis=0)\n",
        "    \n",
        "for tag, count in zip(vocab, dist):\n",
        "    print(count, tag)\n",
        "    \n",
        "pd.DataFrame(dist, columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]] A\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>Aani</th>\n",
              "      <th>Aaron</th>\n",
              "      <th>Aaronic</th>\n",
              "      <th>Aaronical</th>\n",
              "      <th>Aaronite</th>\n",
              "      <th>Aaronitic</th>\n",
              "      <th>Aaru</th>\n",
              "      <th>Ab</th>\n",
              "      <th>Ababdeh</th>\n",
              "      <th>...</th>\n",
              "      <th>zymotechnical</th>\n",
              "      <th>zymotechnics</th>\n",
              "      <th>zymotechny</th>\n",
              "      <th>zymotic</th>\n",
              "      <th>zymotically</th>\n",
              "      <th>zymotize</th>\n",
              "      <th>zymotoxic</th>\n",
              "      <th>zymurgy</th>\n",
              "      <th>zythem</th>\n",
              "      <th>zythum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 235892 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     A  Aani  Aaron  Aaronic  Aaronical  Aaronite  Aaronitic  Aaru   Ab  \\\n",
              "0  0.0   0.0    0.0      0.0        0.0       0.0        0.0   0.0  0.0   \n",
              "\n",
              "   Ababdeh   ...    zymotechnical  zymotechnics  zymotechny  zymotic  \\\n",
              "0      0.0   ...              0.0           0.0         0.0      0.0   \n",
              "\n",
              "   zymotically  zymotize  zymotoxic  zymurgy  zythem  zythum  \n",
              "0          0.0       0.0        0.0      0.0     0.0     0.0  \n",
              "\n",
              "[1 rows x 235892 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHUSDQSUz394",
        "colab_type": "code",
        "colab": {},
        "outputId": "091cd9a6-cfcb-48fe-bbf2-cb2e6535729d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 랜덤포레스트 분류기를 사용\n",
        "forest = RandomForestClassifier(\n",
        "    n_estimators = 100, n_jobs = -1, random_state=2018)\n",
        "forest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "            oob_score=False, random_state=2018, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9b8Om4yz397",
        "colab_type": "code",
        "colab": {},
        "outputId": "ec939261-55b6-45a1-a9eb-df431175d389"
      },
      "source": [
        "%time forest = forest.fit(X_train_tfidf_vector, train['sentiment'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 46s, sys: 2.24 s, total: 4min 48s\n",
            "Wall time: 1min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0JGjACCz39_",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation 교차 검증\n",
        "* 일반화 성능을 측정하기 위해 데이터를 여러 번 반복해서 나누고 여러 모델을 학습한다.\n",
        "![image.png](https://www.researchgate.net/profile/Halil_Bisgin/publication/228403467/figure/fig2/AS:302039595798534@1449023259454/Figure-4-k-fold-cross-validation-scheme-example.png)\n",
        "이미지 출처 : https://www.researchgate.net/figure/228403467_fig2_Figure-4-k-fold-cross-validation-scheme-example\n",
        "\n",
        "\n",
        "* KFold 교차검증 \n",
        "    * 데이터를 폴드라 부르는 비슷한 크기의 부분집합(n_splits)으로 나누고 각각의 폴드 정확도를 측정한다.\n",
        "    * 첫 번째 폴드를 테스트 세트로 사용하고 나머지 폴드를 훈련세트로 사용하여 학습한다.\n",
        "    * 나머지 훈련세트로 만들어진 세트의 정확도를 첫 번째 폴드로 평가한다.\n",
        "    * 다음은 두 번째 폴드가 테스트 세트가 되고 나머지 폴드의 훈련세트를 두 번째 폴드로 정확도를 측정한다.\n",
        "    * 이 과정을 마지막 폴드까지 반복한다.\n",
        "    * 이렇게 훈련세트와 테스트세트로 나누는 N개의 분할마다 정확도를 측정하여 평균 값을 낸게 정확도가 된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsvV_gaFz3-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI_v5hERz3-M",
        "colab_type": "code",
        "colab": {},
        "outputId": "e154dff2-7930-49f1-f190-eaec4f294777"
      },
      "source": [
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
        "\n",
        "%time score = np.mean(cross_val_score(\\\n",
        "    forest, X_train_tfidf_vector, \\\n",
        "    train['sentiment'], cv=k_fold, scoring='roc_auc', n_jobs=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 559 ms, sys: 213 ms, total: 772 ms\n",
            "Wall time: 5min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roA1Nfhmz3-Q",
        "colab_type": "code",
        "colab": {},
        "outputId": "7c9e428d-366a-4295-8d44-3b877e832ae1"
      },
      "source": [
        "# 0.92149\n",
        "'{:,.5f}'.format(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.92068'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKq79qkxz3-T",
        "colab_type": "code",
        "colab": {},
        "outputId": "162b56da-ab8b-4844-8b4e-65550a89f398"
      },
      "source": [
        "%time result = forest.predict(X_test_tfidf_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.97 s, sys: 138 ms, total: 5.11 s\n",
            "Wall time: 1.78 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdeOclE4z3-V",
        "colab_type": "code",
        "colab": {},
        "outputId": "9e3dd480-ebb7-4264-f6df-b55ad3714e26"
      },
      "source": [
        "result[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMp0-EJz3-Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "6d98057b-22a7-4e21-a25f-c0327586ef37"
      },
      "source": [
        "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
        "output.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"          1\n",
              "1    \"8348_2\"          0\n",
              "2    \"5828_4\"          0\n",
              "3    \"7186_2\"          0\n",
              "4   \"12128_7\"          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkQy_BB6z3-d",
        "colab_type": "code",
        "colab": {},
        "outputId": "726bffee-988e-45e8-d122-dc0687c3c184"
      },
      "source": [
        "output_sentiment = output['sentiment'].value_counts()\n",
        "print(output_sentiment[0] - output_sentiment[1])\n",
        "output_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12688\n",
              "0    12312\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Noxch1Vuz3-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_csv('data/tutorial_4_tfidf_{0:.5f}.csv'.format(score), index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jLt-a_Fz3-l",
        "colab_type": "code",
        "colab": {},
        "outputId": "451222e0-8c2e-48b1-aefe-979a5f5cac58"
      },
      "source": [
        "# 그런데 점수가 너무 낮게 나옴\n",
        "# local 0.92149 kaggle 0.84392\n",
        "# stop_words = 'english' vocabulary = set(words.words()), smooth_idf = False\n",
        "468/578"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8096885813148789"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4UR6Uh1z3-o",
        "colab_type": "text"
      },
      "source": [
        "## XGBoost: A Scalable Tree Boosting System\n",
        "* 2015년 캐글 블로그에 xgboost를 사용하여 17건의 우승 솔루션이 공유됨 :  [Dato Winners’ Interview: 1st place, Mad Professors | No Free Hunch](http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/)\n",
        "* 2016년 논문이 등록 됨 : [XGBoostArxiv.pdf](http://dmlc.cs.washington.edu/data/pdf/XGBoostArxiv.pdf)\n",
        "* 공식문서 : [XGBoost Documents](https://xgboost.readthedocs.io/en/latest/)\n",
        "* 분산형 그래디언트 부스팅 알고리즘\n",
        "* 부스팅 알고리즘은?\n",
        "    * 부스팅 알고리즘은 약한 예측모형들을 결합하여 강한 예측모형을 만드는 알고리즘\n",
        "    * 배깅과 유사하게 초기 샘플데이터로 다수의 분류기를 만들지만 배깅과 다르게 순차적이다.\n",
        "    * 랜덤포레스트의 배깅과는 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦\n",
        "    * 결정트리(Decision Tree) 알고리즘의 연장선에 있음\n",
        "    * 여러 개의 결정트리를 묶어 강력한 모델을 만드는 앙상블 방법\n",
        "    * 분류와 회귀에 사용할 수 있음\n",
        "    * 무작위성이 없으며 강력한 사전 가지치기를 사용\n",
        "    * 참고 이미지 : http://www.birc.co.kr/2017/02/06/%EC%95%99%EC%83%81%EB%B8%94ensemble-%EB%B6%80%EC%8A%A4%ED%8C%85boosting/\n",
        "    * 배깅과 부스팅의 차이점은 udacity에서 설명한 영상이 가장 도움이 되었음\n",
        "        * 배깅 : https://www.youtube.com/watch?v=2Mg8QD0F1dQ\n",
        "        * 부스팅 : https://www.youtube.com/watch?v=GM3CDQfQ4sw\n",
        "* 타이타닉 경진대회에 사용 예제가 있음 [XGBoost example (Python) | Kaggle](https://www.kaggle.com/datacanary/xgboost-example-python/)\n",
        "\n",
        "\n",
        "## [Mac OSX에서 XGBoost 설치하기](http://corazzon.github.io/xgboost-install-mac-osx)\n",
        "* http://corazzon.github.io/xgboost-install-mac-osx\n",
        "\n",
        "* [A Gentle Introduction to XGBoost for Applied Machine Learning - Machine Learning Mastery](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)\n",
        "\n",
        "* https://speakerdeck.com/datasciencela/tianqi-chen-xgboost-overview-and-latest-news-la-meetup-talk\n",
        "\n",
        "* datacamp의 XGboost 온라인 강의 : [Extreme Gradient Boosting with XGBoost](https://www.datacamp.com/courses/extreme-gradient-boosting-with-xgboost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRCTLeZEz3-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train_tfidf_vector, label=train['sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvZkWQZez3-q",
        "colab_type": "code",
        "colab": {},
        "outputId": "d6d9e9d8-7f96-468a-fbb1-8585d4b73a9d"
      },
      "source": [
        "# 멀티프로세싱은 nthread 였는데 n_jobs로 변경되었다고 한다.\n",
        "# 설치 된 xgboost버전에 따라 파라메터가 다를 수 있으니 \n",
        "# 이 코드를 돌리고 터미널에서 $ top -o cpu 로 CPU자원을 100%넘게 사용하고 있는지 확인해 본다.\n",
        "params = {\n",
        "    'booster': 'gblinear',\n",
        "    'objective': 'multi:softmax',\n",
        "    'eval_metric': 'merror',\n",
        "    'eta' : 0.02,\n",
        "    'lambda': 2.0,\n",
        "    'alpha': 1.0,\n",
        "    'lambda_bias': 6.0,\n",
        "    'num_class': 5,\n",
        "    'n_jobs' : 4,\n",
        "    'silent': 1,\n",
        "}\n",
        "\n",
        "%time booster = xgb.train(params, dtrain, num_boost_round=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.2 s, sys: 1.19 s, total: 25.4 s\n",
            "Wall time: 18.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIYMnL_nz3-t",
        "colab_type": "code",
        "colab": {},
        "outputId": "24ca359d-f4d5-4927-a471-38f3bd373366"
      },
      "source": [
        "dtest = xgb.DMatrix(X_test_tfidf_vector)\n",
        "\n",
        "result = booster.predict(dtest)\n",
        "\n",
        "print(result.shape)\n",
        "result[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 1., 1., 1., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIv3NJmOz3-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = result.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nevgVaipz3-0",
        "colab_type": "code",
        "colab": {},
        "outputId": "2d3a7109-f200-45e9-e0b5-210e2fd934bf"
      },
      "source": [
        "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
        "output.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"          1\n",
              "1    \"8348_2\"          0\n",
              "2    \"5828_4\"          1\n",
              "3    \"7186_2\"          1\n",
              "4   \"12128_7\"          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWJVQgvQz3-3",
        "colab_type": "code",
        "colab": {},
        "outputId": "28b03315-7f20-4a64-a077-70e4815c9161"
      },
      "source": [
        "output_sentiment = output['sentiment'].value_counts()\n",
        "print(output_sentiment[0] - output_sentiment[1])\n",
        "output_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12852\n",
              "0    12148\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0brBwLIqz3-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_csv(\"data/tutorial_4_tfidf_xgboost.csv\", index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRVHlRmWz3--",
        "colab_type": "text"
      },
      "source": [
        "### Kaggle API를 통해 서브미션이 가능하다.\n",
        "* [Kaggle/kaggle-api: Official Kaggle API](https://github.com/Kaggle/kaggle-api)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5GOsZ64z3-_",
        "colab_type": "code",
        "colab": {},
        "outputId": "0f1b17e5-0d00-4d00-9238-f3d770d444da"
      },
      "source": [
        "# !kaggle competitions submit -c word2vec-nlp-tutorial -f data/tutorial_4_tfidf_xgboost.csv -m 'num_boost_round=300'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully submitted to Bag of Words Meets Bags of Popcorn"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eK0v0bPz3_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !kaggle competitions submissions -c word2vec-nlp-tutorial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jp_Y5_qz3_F",
        "colab_type": "code",
        "colab": {},
        "outputId": "1115c6cf-31da-429b-aee4-de4003ba4b55"
      },
      "source": [
        "# 캐글 스코어 0.86560\n",
        "286/578"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49480968858131485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFz5hceJz3_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}